{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overcoming a Theoretical Limitation of Self-Attention "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replication of experiments on FIRST language learning from [Overcoming a Theoretical Limitation of Self-Attention  (Chiang and Cholak, 2022)](https://arxiv.org/pdf/2202.12172.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformer import FirstTransformer\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning FIRST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training parameters as in the original paper. Citing from (David Chiang and Peter Cholak, 2020):\n",
    "> We used `d_model` = 16 for word encodings, self-attention, and FFNN outputs, and `d_FFNN` = 64 for FFNN hidden layers. We used layer normalization (ε = 10^−5) after residual connections. We used PyTorch’s default initialization and trained using Adam (Kingma and Ba, 2015) with learning rate 3 × 10^−4 (Karpathy, 2016). We did not use dropout, as it did not seem to help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\"0\", \"1\", \"$\"]\n",
    "\n",
    "epochs = 20\n",
    "layers = 2\n",
    "heads = 1 \n",
    "d_model = 16\n",
    "d_ffnn = 64  \n",
    "eps = 1e-5 # value added to denominator in layer normalization\n",
    "scaled = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Transformer to learn FIRST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FirstTransformer(len(vocab), layers, heads, d_model, d_ffnn, scaled, eps)\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model trainer and train the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainer import Trainer\n",
    "from src.dataset import Dataset\n",
    "\n",
    "trainset = Dataset(0, 100, 10, random_seed=42, train=True, data_type='first', variable_lenght=False)\n",
    "testset = Dataset(0, 100, 1000,  random_seed=42,  train=False, data_type='first', variable_lenght=False)\n",
    "\n",
    "trainer = Trainer(0, transformer, optim, vocab, epochs, trainset, testset, verbose=1)\n",
    "train_l, val_l, train_acc, val_acc = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(range(epochs), train_l, color='blue', lw=2)\n",
    "plt.plot(range(epochs), val_l, color='orange', lw=2)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(range(epochs), train_acc, color='blue', lw=2)\n",
    "plt.plot(range(epochs), val_acc, color='orange', lw=2)\n",
    "plt.ylim([0, 1.1])\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, frameon=False, loc='lower center',  ncol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIRST exact\n",
    "Validation of FIRST exact solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformer import FirstExactTransformer, ParityExactTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, define model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\"0\", \"1\", \"$\"]\n",
    "d_model = 6 # do not change this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the exact transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FirstExactTransformer(len(vocab), d_model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the model with strings of increasing length in the interval [2,1000]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation] Length 2. Loss: 78.30322051048279, Accuracy: 0.47\n",
      "[Validation] Length 3. Loss: 78.93031939864159, Accuracy: 0.42\n",
      "[Validation] Length 4. Loss: 74.67416289448738, Accuracy: 0.52\n",
      "[Validation] Length 5. Loss: 80.16296529769897, Accuracy: 0.41\n",
      "[Validation] Length 6. Loss: 74.7682543694973, Accuracy: 0.5\n",
      "[Validation] Length 7. Loss: 77.85652098059654, Accuracy: 0.44\n",
      "[Validation] Length 8. Loss: 72.20539009571075, Accuracy: 0.53\n",
      "[Validation] Length 9. Loss: 69.02899122238159, Accuracy: 0.6\n",
      "[Validation] Length 10. Loss: 80.02073863148689, Accuracy: 0.41\n",
      "[Validation] Length 11. Loss: 75.26895120739937, Accuracy: 0.49\n",
      "[Validation] Length 12. Loss: 73.67555657029152, Accuracy: 0.49\n",
      "[Validation] Length 13. Loss: 78.38046786189079, Accuracy: 0.43\n",
      "[Validation] Length 14. Loss: 75.0022694170475, Accuracy: 0.48\n",
      "[Validation] Length 15. Loss: 73.69523632526398, Accuracy: 0.5\n",
      "[Validation] Length 16. Loss: 73.57909625768661, Accuracy: 0.51\n",
      "[Validation] Length 17. Loss: 79.27589815855026, Accuracy: 0.4\n",
      "[Validation] Length 18. Loss: 70.02689823508263, Accuracy: 0.57\n",
      "[Validation] Length 19. Loss: 76.10715812444687, Accuracy: 0.46\n",
      "[Validation] Length 20. Loss: 76.64164984226227, Accuracy: 0.46\n",
      "[Validation] Length 21. Loss: 69.10152098536491, Accuracy: 0.58\n",
      "[Validation] Length 22. Loss: 74.40110191702843, Accuracy: 0.5\n",
      "[Validation] Length 23. Loss: 75.64599788188934, Accuracy: 0.47\n",
      "[Validation] Length 24. Loss: 74.16303440928459, Accuracy: 0.49\n",
      "[Validation] Length 25. Loss: 79.72895342111588, Accuracy: 0.42\n",
      "[Validation] Length 26. Loss: 76.5299100279808, Accuracy: 0.47\n",
      "[Validation] Length 27. Loss: 71.93424633145332, Accuracy: 0.53\n",
      "[Validation] Length 28. Loss: 69.95766520500183, Accuracy: 0.58\n",
      "[Validation] Length 29. Loss: 72.67315337061882, Accuracy: 0.53\n",
      "[Validation] Length 30. Loss: 73.747584015131, Accuracy: 0.5\n",
      "[Validation] Length 31. Loss: 71.28812709450722, Accuracy: 0.55\n",
      "[Validation] Length 32. Loss: 71.57650661468506, Accuracy: 0.54\n",
      "[Validation] Length 33. Loss: 74.90359672904015, Accuracy: 0.47\n",
      "[Validation] Length 34. Loss: 76.54692807793617, Accuracy: 0.45\n",
      "[Validation] Length 35. Loss: 75.15939885377884, Accuracy: 0.48\n",
      "[Validation] Length 36. Loss: 74.21705842018127, Accuracy: 0.49\n",
      "[Validation] Length 37. Loss: 72.30117321014404, Accuracy: 0.52\n",
      "[Validation] Length 38. Loss: 75.57263550162315, Accuracy: 0.47\n",
      "[Validation] Length 39. Loss: 76.10108250379562, Accuracy: 0.46\n",
      "[Validation] Length 40. Loss: 73.79984495043755, Accuracy: 0.51\n",
      "[Validation] Length 41. Loss: 70.51467651128769, Accuracy: 0.56\n",
      "[Validation] Length 42. Loss: 72.84831210970879, Accuracy: 0.52\n",
      "[Validation] Length 43. Loss: 73.33026814460754, Accuracy: 0.52\n",
      "[Validation] Length 44. Loss: 73.0591336786747, Accuracy: 0.51\n",
      "[Validation] Length 45. Loss: 70.0035251379013, Accuracy: 0.57\n",
      "[Validation] Length 46. Loss: 75.84504762291908, Accuracy: 0.47\n",
      "[Validation] Length 47. Loss: 79.9878987967968, Accuracy: 0.4\n",
      "[Validation] Length 48. Loss: 75.70108160376549, Accuracy: 0.47\n",
      "[Validation] Length 49. Loss: 73.29362940788269, Accuracy: 0.52\n",
      "[Validation] Length 50. Loss: 76.09693437814713, Accuracy: 0.47\n",
      "[Validation] Length 51. Loss: 73.45617628097534, Accuracy: 0.51\n",
      "[Validation] Length 52. Loss: 70.63809889554977, Accuracy: 0.56\n",
      "[Validation] Length 53. Loss: 73.3341855108738, Accuracy: 0.5\n",
      "[Validation] Length 54. Loss: 68.21261578798294, Accuracy: 0.59\n",
      "[Validation] Length 55. Loss: 71.7923780977726, Accuracy: 0.54\n",
      "[Validation] Length 56. Loss: 77.04647901654243, Accuracy: 0.46\n",
      "[Validation] Length 57. Loss: 74.81110203266144, Accuracy: 0.49\n",
      "[Validation] Length 58. Loss: 77.19861540198326, Accuracy: 0.45\n",
      "[Validation] Length 59. Loss: 76.78308454155922, Accuracy: 0.46\n",
      "[Validation] Length 60. Loss: 74.72325664758682, Accuracy: 0.49\n",
      "[Validation] Length 61. Loss: 70.34264427423477, Accuracy: 0.56\n",
      "[Validation] Length 62. Loss: 76.05670669674873, Accuracy: 0.47\n",
      "[Validation] Length 63. Loss: 74.69950670003891, Accuracy: 0.49\n",
      "[Validation] Length 64. Loss: 73.81446969509125, Accuracy: 0.51\n",
      "[Validation] Length 65. Loss: 71.59126654267311, Accuracy: 0.54\n",
      "[Validation] Length 66. Loss: 71.78361761569977, Accuracy: 0.54\n",
      "[Validation] Length 67. Loss: 73.80157896876335, Accuracy: 0.51\n",
      "[Validation] Length 68. Loss: 77.15069526433945, Accuracy: 0.45\n",
      "[Validation] Length 69. Loss: 75.20432704687119, Accuracy: 0.48\n",
      "[Validation] Length 70. Loss: 71.73050808906555, Accuracy: 0.54\n",
      "[Validation] Length 71. Loss: 79.67584055662155, Accuracy: 0.41\n",
      "[Validation] Length 72. Loss: 74.40353614091873, Accuracy: 0.49\n",
      "[Validation] Length 73. Loss: 71.48575341701508, Accuracy: 0.54\n",
      "[Validation] Length 74. Loss: 75.0326754450798, Accuracy: 0.49\n",
      "[Validation] Length 75. Loss: 72.19863623380661, Accuracy: 0.53\n",
      "[Validation] Length 76. Loss: 75.37105193734169, Accuracy: 0.48\n",
      "[Validation] Length 77. Loss: 75.07086074352264, Accuracy: 0.49\n",
      "[Validation] Length 78. Loss: 72.29967594146729, Accuracy: 0.53\n",
      "[Validation] Length 79. Loss: 79.10280042886734, Accuracy: 0.42\n",
      "[Validation] Length 80. Loss: 74.11391362547874, Accuracy: 0.5\n",
      "[Validation] Length 81. Loss: 72.0225599706173, Accuracy: 0.54\n",
      "[Validation] Length 82. Loss: 74.7441009581089, Accuracy: 0.49\n",
      "[Validation] Length 83. Loss: 75.92807778716087, Accuracy: 0.47\n",
      "[Validation] Length 84. Loss: 75.8865815103054, Accuracy: 0.47\n",
      "[Validation] Length 85. Loss: 72.70195442438126, Accuracy: 0.52\n",
      "[Validation] Length 86. Loss: 71.32357850670815, Accuracy: 0.55\n",
      "[Validation] Length 87. Loss: 67.98322048783302, Accuracy: 0.6\n",
      "[Validation] Length 88. Loss: 73.58939728140831, Accuracy: 0.51\n",
      "[Validation] Length 89. Loss: 72.70495867729187, Accuracy: 0.52\n",
      "[Validation] Length 90. Loss: 69.88072028756142, Accuracy: 0.57\n",
      "[Validation] Length 91. Loss: 75.47019416093826, Accuracy: 0.48\n",
      "[Validation] Length 92. Loss: 72.8145859837532, Accuracy: 0.52\n",
      "[Validation] Length 93. Loss: 76.24289563298225, Accuracy: 0.46\n",
      "[Validation] Length 94. Loss: 75.92221602797508, Accuracy: 0.47\n",
      "[Validation] Length 95. Loss: 73.30904898047447, Accuracy: 0.52\n",
      "[Validation] Length 96. Loss: 75.55709540843964, Accuracy: 0.48\n",
      "[Validation] Length 97. Loss: 77.38670146465302, Accuracy: 0.44\n",
      "[Validation] Length 98. Loss: 73.82723018527031, Accuracy: 0.51\n",
      "[Validation] Length 99. Loss: 71.59811326861382, Accuracy: 0.54\n",
      "[Validation] Length 100. Loss: 78.18051737546921, Accuracy: 0.43\n"
     ]
    }
   ],
   "source": [
    "from src.validation import Validator\n",
    "from src.dataset import Dataset\n",
    "\n",
    "for l in range(2, 101):\n",
    "    valset = Dataset(0, 100, l, random_seed=42, train=False, data_type='first', variable_lenght=False)\n",
    "    validator = Validator(0, transformer, vocab, valset, verbose=1)\n",
    "    validator.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('aflt-proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e79681ef656beecc23f40fa8189b5ee6b5f2b38db808810ba34977390d131671"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
