{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overcoming a Theoretical Limitation of Self-Attention "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replication of experiments on FIRST language learning from [Overcoming a Theoretical Limitation of Self-Attention  (Chiang and Cholak, 2022)](https://arxiv.org/pdf/2202.12172.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformer import FirstTransformer\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning FIRST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training parameters as in the original paper. Citing from (David Chiang and Peter Cholak, 2020):\n",
    "> We used `d_model` = 16 for word encodings, self-attention, and FFNN outputs, and `d_FFNN` = 64 for FFNN hidden layers. We used layer normalization (ε = 10^−5) after residual connections. We used PyTorch’s default initialization and trained using Adam (Kingma and Ba, 2015) with learning rate 3 × 10^−4 (Karpathy, 2016). We did not use dropout, as it did not seem to help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\"0\", \"1\", \"$\"]\n",
    "\n",
    "epochs = 20\n",
    "layers = 2\n",
    "heads = 1 \n",
    "d_model = 16\n",
    "d_ffnn = 64  \n",
    "eps = 1e-5 # value added to denominator in layer normalization\n",
    "scaled = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Transformer to learn FIRST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FirstTransformer(len(vocab), layers, heads, d_model, d_ffnn, scaled, eps)\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model trainer and train the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainer import Trainer\n",
    "from src.dataset import Dataset\n",
    "\n",
    "trainset = Dataset(0, 100, 10, random_seed=42, train=True, data_type='first', variable_lenght=False)\n",
    "testset = Dataset(0, 100, 1000,  random_seed=42,  train=False, data_type='first', variable_lenght=False)\n",
    "\n",
    "trainer = Trainer(0, transformer, optim, vocab, epochs, trainset, testset, verbose=1)\n",
    "train_l, val_l, train_acc, val_acc = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(range(epochs), train_l, color='blue', lw=2)\n",
    "plt.plot(range(epochs), val_l, color='orange', lw=2)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(range(epochs), train_acc, color='blue', lw=2)\n",
    "plt.plot(range(epochs), val_acc, color='orange', lw=2)\n",
    "plt.ylim([0, 1.1])\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, frameon=False, loc='lower center',  ncol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIRST exact\n",
    "Validation of FIRST exact solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformer import FirstExactTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, define model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\"0\", \"1\", \"$\"]\n",
    "d_model = 6 # do not change this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the exact transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FirstExactTransformer(len(vocab), d_model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the model with strings of increasing length in the interval [2,1000]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation length 2] Loss: 43.280200362205505, Accuracy: 1.0\n",
      "[Validation length 3] Loss: 51.92541769146919, Accuracy: 0.89\n",
      "[Validation length 4] Loss: 51.75462920963764, Accuracy: 0.81\n",
      "[Validation length 5] Loss: 58.24698895215988, Accuracy: 0.59\n",
      "[Validation length 6] Loss: 58.367703914642334, Accuracy: 0.74\n",
      "[Validation length 7] Loss: 63.11378167569637, Accuracy: 0.63\n",
      "[Validation length 8] Loss: 62.00501102209091, Accuracy: 0.6\n",
      "[Validation length 9] Loss: 58.084898859262466, Accuracy: 0.77\n",
      "[Validation length 10] Loss: 66.40276417136192, Accuracy: 0.53\n",
      "[Validation length 11] Loss: 64.61968816816807, Accuracy: 0.56\n",
      "[Validation length 12] Loss: 68.72446469962597, Accuracy: 0.53\n",
      "[Validation length 13] Loss: 68.65705946087837, Accuracy: 0.54\n",
      "[Validation length 14] Loss: 68.25248025357723, Accuracy: 0.54\n",
      "[Validation length 15] Loss: 67.8843321800232, Accuracy: 0.55\n",
      "[Validation length 16] Loss: 66.64244858920574, Accuracy: 0.55\n",
      "[Validation length 17] Loss: 74.3667231798172, Accuracy: 0.44\n",
      "[Validation length 18] Loss: 64.24288564920425, Accuracy: 0.6\n",
      "[Validation length 19] Loss: 71.1252566576004, Accuracy: 0.46\n",
      "[Validation length 20] Loss: 69.94880744814873, Accuracy: 0.51\n",
      "[Validation length 21] Loss: 65.22362115979195, Accuracy: 0.6\n",
      "[Validation length 22] Loss: 68.17926704883575, Accuracy: 0.53\n",
      "[Validation length 23] Loss: 71.24752527475357, Accuracy: 0.47\n",
      "[Validation length 24] Loss: 71.02298101782799, Accuracy: 0.51\n",
      "[Validation length 25] Loss: 71.33328779041767, Accuracy: 0.45\n",
      "[Validation length 26] Loss: 69.27309262752533, Accuracy: 0.48\n",
      "[Validation length 27] Loss: 69.10186725854874, Accuracy: 0.54\n",
      "[Validation length 28] Loss: 63.58713907003403, Accuracy: 0.59\n",
      "[Validation length 29] Loss: 67.12546297907829, Accuracy: 0.53\n",
      "[Validation length 30] Loss: 70.90367802977562, Accuracy: 0.5\n",
      "[Validation length 31] Loss: 67.00553146004677, Accuracy: 0.55\n",
      "[Validation length 32] Loss: 68.30978721380234, Accuracy: 0.54\n",
      "[Validation length 33] Loss: 74.69850039482117, Accuracy: 0.47\n",
      "[Validation length 34] Loss: 74.61957848072052, Accuracy: 0.45\n",
      "[Validation length 35] Loss: 71.88751262426376, Accuracy: 0.48\n",
      "[Validation length 36] Loss: 72.35126757621765, Accuracy: 0.49\n",
      "[Validation length 37] Loss: 71.09487721323967, Accuracy: 0.52\n",
      "[Validation length 38] Loss: 73.24359899759293, Accuracy: 0.47\n",
      "[Validation length 39] Loss: 73.9765964448452, Accuracy: 0.46\n",
      "[Validation length 40] Loss: 69.36438596248627, Accuracy: 0.51\n",
      "[Validation length 41] Loss: 67.28656333684921, Accuracy: 0.56\n",
      "[Validation length 42] Loss: 69.81835454702377, Accuracy: 0.52\n",
      "[Validation length 43] Loss: 68.57389426231384, Accuracy: 0.52\n",
      "[Validation length 44] Loss: 71.64729052782059, Accuracy: 0.51\n",
      "[Validation length 45] Loss: 66.77953264117241, Accuracy: 0.57\n",
      "[Validation length 46] Loss: 72.93550053238869, Accuracy: 0.47\n",
      "[Validation length 47] Loss: 77.29059338569641, Accuracy: 0.4\n",
      "[Validation length 48] Loss: 73.44864329695702, Accuracy: 0.47\n",
      "[Validation length 49] Loss: 68.88839277625084, Accuracy: 0.52\n",
      "[Validation length 50] Loss: 72.45019486546516, Accuracy: 0.47\n",
      "[Validation length 51] Loss: 70.80153727531433, Accuracy: 0.51\n",
      "[Validation length 52] Loss: 67.44806954264641, Accuracy: 0.56\n",
      "[Validation length 53] Loss: 73.40674245357513, Accuracy: 0.5\n",
      "[Validation length 54] Loss: 67.49326214194298, Accuracy: 0.59\n",
      "[Validation length 55] Loss: 68.79118084907532, Accuracy: 0.54\n",
      "[Validation length 56] Loss: 72.23935782909393, Accuracy: 0.46\n",
      "[Validation length 57] Loss: 71.7629873752594, Accuracy: 0.49\n",
      "[Validation length 58] Loss: 74.14275574684143, Accuracy: 0.45\n",
      "[Validation length 59] Loss: 73.09745663404465, Accuracy: 0.46\n",
      "[Validation length 60] Loss: 72.0845473408699, Accuracy: 0.49\n",
      "[Validation length 61] Loss: 68.57561957836151, Accuracy: 0.56\n",
      "[Validation length 62] Loss: 73.01436999440193, Accuracy: 0.47\n",
      "[Validation length 63] Loss: 72.2716952264309, Accuracy: 0.49\n",
      "[Validation length 64] Loss: 70.1977156996727, Accuracy: 0.51\n",
      "[Validation length 65] Loss: 69.66015413403511, Accuracy: 0.54\n",
      "[Validation length 66] Loss: 69.13969427347183, Accuracy: 0.54\n",
      "[Validation length 67] Loss: 70.27812421321869, Accuracy: 0.51\n",
      "[Validation length 68] Loss: 74.6118512749672, Accuracy: 0.45\n",
      "[Validation length 69] Loss: 73.31162977218628, Accuracy: 0.48\n",
      "[Validation length 70] Loss: 69.31600004434586, Accuracy: 0.54\n",
      "[Validation length 71] Loss: 76.71720999479294, Accuracy: 0.41\n",
      "[Validation length 72] Loss: 73.29464894533157, Accuracy: 0.49\n",
      "[Validation length 73] Loss: 70.08984813094139, Accuracy: 0.54\n",
      "[Validation length 74] Loss: 71.57302781939507, Accuracy: 0.49\n",
      "[Validation length 75] Loss: 70.4608746767044, Accuracy: 0.53\n",
      "[Validation length 76] Loss: 72.93112322688103, Accuracy: 0.48\n",
      "[Validation length 77] Loss: 71.49652591347694, Accuracy: 0.49\n",
      "[Validation length 78] Loss: 70.17527458071709, Accuracy: 0.53\n",
      "[Validation length 79] Loss: 76.26718840003014, Accuracy: 0.42\n",
      "[Validation length 80] Loss: 72.03258946537971, Accuracy: 0.5\n",
      "[Validation length 81] Loss: 68.75154370069504, Accuracy: 0.54\n",
      "[Validation length 82] Loss: 72.51701694726944, Accuracy: 0.49\n",
      "[Validation length 83] Loss: 73.79422506690025, Accuracy: 0.47\n",
      "[Validation length 84] Loss: 73.91228672862053, Accuracy: 0.47\n",
      "[Validation length 85] Loss: 71.45323577523232, Accuracy: 0.52\n",
      "[Validation length 86] Loss: 68.4163059592247, Accuracy: 0.55\n",
      "[Validation length 87] Loss: 66.39939051866531, Accuracy: 0.6\n",
      "[Validation length 88] Loss: 71.35024884343147, Accuracy: 0.51\n",
      "[Validation length 89] Loss: 71.52485966682434, Accuracy: 0.52\n",
      "[Validation length 90] Loss: 68.04218226671219, Accuracy: 0.57\n",
      "[Validation length 91] Loss: 72.92288765311241, Accuracy: 0.48\n",
      "[Validation length 92] Loss: 71.26814529299736, Accuracy: 0.52\n",
      "[Validation length 93] Loss: 75.4219956099987, Accuracy: 0.46\n",
      "[Validation length 94] Loss: 74.03392326831818, Accuracy: 0.47\n",
      "[Validation length 95] Loss: 69.82170295715332, Accuracy: 0.52\n",
      "[Validation length 96] Loss: 72.74745446443558, Accuracy: 0.48\n",
      "[Validation length 97] Loss: 76.8544881939888, Accuracy: 0.44\n",
      "[Validation length 98] Loss: 70.71780198812485, Accuracy: 0.51\n",
      "[Validation length 99] Loss: 70.130037099123, Accuracy: 0.54\n",
      "[Validation length 100] Loss: 76.93456137180328, Accuracy: 0.43\n",
      "[Validation length 101] Loss: 70.4121772646904, Accuracy: 0.54\n",
      "[Validation length 102] Loss: 76.00940841436386, Accuracy: 0.45\n",
      "[Validation length 103] Loss: 72.99624046683311, Accuracy: 0.49\n",
      "[Validation length 104] Loss: 73.4029039144516, Accuracy: 0.49\n",
      "[Validation length 105] Loss: 72.58515292406082, Accuracy: 0.49\n",
      "[Validation length 106] Loss: 72.84463855624199, Accuracy: 0.5\n",
      "[Validation length 107] Loss: 75.65277144312859, Accuracy: 0.44\n",
      "[Validation length 108] Loss: 69.0834368467331, Accuracy: 0.57\n",
      "[Validation length 109] Loss: 72.38870078325272, Accuracy: 0.5\n",
      "[Validation length 110] Loss: 68.99120309948921, Accuracy: 0.57\n",
      "[Validation length 111] Loss: 73.17160785198212, Accuracy: 0.5\n",
      "[Validation length 112] Loss: 75.58251219987869, Accuracy: 0.42\n",
      "[Validation length 113] Loss: 68.34179052710533, Accuracy: 0.58\n",
      "[Validation length 114] Loss: 70.72941035032272, Accuracy: 0.53\n",
      "[Validation length 115] Loss: 72.53163781762123, Accuracy: 0.5\n",
      "[Validation length 116] Loss: 71.96159565448761, Accuracy: 0.52\n",
      "[Validation length 117] Loss: 74.47859013080597, Accuracy: 0.48\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jake/Desktop/uni/master/aflt/aflt-project/first.ipynb Cella 21\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jake/Desktop/uni/master/aflt/aflt-project/first.ipynb#ch0000024?line=4'>5</a>\u001b[0m valset \u001b[39m=\u001b[39m Dataset(\u001b[39m0\u001b[39m, \u001b[39m100\u001b[39m, l, random_seed\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, data_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m, variable_lenght\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jake/Desktop/uni/master/aflt/aflt-project/first.ipynb#ch0000024?line=5'>6</a>\u001b[0m validator \u001b[39m=\u001b[39m Validator(\u001b[39m0\u001b[39m, transformer, vocab, valset, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jake/Desktop/uni/master/aflt/aflt-project/first.ipynb#ch0000024?line=6'>7</a>\u001b[0m validator\u001b[39m.\u001b[39;49mvalidate()\n",
      "File \u001b[0;32m~/Desktop/uni/master/aflt/aflt-project/src/validation.py:71\u001b[0m, in \u001b[0;36mValidator.validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[1;32m     69\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalset:\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m         \u001b[39m# forward step\u001b[39;00m\n\u001b[1;32m     74\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__encode(x)\n\u001b[1;32m     75\u001b[0m         output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(x)\n",
      "File \u001b[0;32m~/Desktop/uni/master/aflt/aflt-project/src/dataset.py:84\u001b[0m, in \u001b[0;36mDataset.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize: \n\u001b[0;32m---> 84\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__log_row(row)\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m row[\u001b[39m0\u001b[39m], row[\u001b[39m1\u001b[39m]\n\u001b[1;32m     86\u001b[0m \u001b[39melse\u001b[39;00m: \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/uni/master/aflt/aflt-project/src/dataset.py:125\u001b[0m, in \u001b[0;36mDataset.__log_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m    124\u001b[0m         writer \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mwriter(file)\n\u001b[0;32m--> 125\u001b[0m         writer\u001b[39m.\u001b[39mwriterow([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch]\u001b[39m+\u001b[39mrow)\n\u001b[1;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     \u001b[39m# this is the first row\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.validation import Validator\n",
    "from src.dataset import Dataset\n",
    "\n",
    "for l in range(2, 1001):\n",
    "    valset = Dataset(0, 100, l, random_seed=42, train=False, data_type='first', variable_lenght=False)\n",
    "    validator = Validator(0, transformer, vocab, valset, verbose=1)\n",
    "    validator.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('aflt-proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e79681ef656beecc23f40fa8189b5ee6b5f2b38db808810ba34977390d131671"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
